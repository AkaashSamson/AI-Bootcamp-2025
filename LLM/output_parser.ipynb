{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a57b9b9a44ab68bbad0fb0bff2dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = \"Can you give me an interesting fact I probably didn't know about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'d love to!\\n\\nHere\\'s one:\\n\\nDid you know that there is a type of jellyfish that is immortal? The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This', additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=100, prompt_tokens=24, total_tokens=124), 'model': '', 'finish_reason': 'length'}, id='run-0945174e-ad3f-4893-ac8e-3b4472b99921-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd love to!\n",
      "\n",
      "Here's one:\n",
      "\n",
      "Did you know that there is a type of jellyfish that is immortal? The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This\n"
     ]
    }
   ],
   "source": [
    "response_parsed = str_output_parser.invoke(response)\n",
    "print(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h = HumanMessage(content = f''' I've recently adopted a dog. Could you suggest some dog names? \n",
    "\n",
    "{CommaSeparatedListOutputParser().get_format_instructions()}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I've recently adopted a dog. Could you suggest some dog names? \n",
      "\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(message_h.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations on the new furry family member! I'd be happy to help you with some dog name suggestions. Here are a few:\n",
      "\n",
      "Rufus, Max, Bella, Charlie, Luna, Rocky, Duke, Daisy, Buddy, Gracie, Cooper, Maggie, Bear, Lola, Winston, Ginger, Cody, Sophie\n",
      "\n",
      "Let me know if you have any specific preferences (e.g., breed, theme, personality) and I can give you more tailored suggestions!\n"
     ]
    }
   ],
   "source": [
    "response = chat.invoke([message_h])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_output_parser = CommaSeparatedListOutputParser()\n",
    "response_parsed = list_output_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Congratulations on the new furry family member! I'd be happy to help you with some dog name suggestions. Here are a few:\",\n",
       " 'Rufus',\n",
       " 'Max',\n",
       " 'Bella',\n",
       " 'Charlie',\n",
       " 'Luna',\n",
       " 'Rocky',\n",
       " 'Duke',\n",
       " 'Daisy',\n",
       " 'Buddy',\n",
       " 'Gracie',\n",
       " 'Cooper',\n",
       " 'Maggie',\n",
       " 'Bear',\n",
       " 'Lola',\n",
       " 'Winston',\n",
       " 'Ginger',\n",
       " 'Cody',\n",
       " 'Sophie',\n",
       " 'Let me know if you have any specific preferences (e.g.',\n",
       " 'breed',\n",
       " 'theme',\n",
       " 'personality) and I can give you more tailored suggestions!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "message_h = HumanMessage(content = \"What is the current date and time?\")\n",
    "response = chat.invoke([message_h])\n",
    "datetime_output_parser = DateTimeOutputParser()\n",
    "response_parsed = datetime_output_parser.invoke(response)\n",
    "print(response_parsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
