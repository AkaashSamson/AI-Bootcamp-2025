{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import (ConversationBufferMemory, \n",
    "                              ConversationSummaryMemory, \n",
    "                              CombinedMemory)\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded from .env file\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"COHERE_API_KEY\"):\n",
    "  os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter API key for Cohere: \")\n",
    "else:\n",
    "    print(\"API key loaded from .env file\")\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "chat  = ChatCohere(model=\"command-r-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c1dd47e0c440e7b2e36acdccb69108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369c630e945140a0a9a991ec43ccdff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071a8dec482d407b8049c42e5dcd9dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfb1fecdf6947929039e1c52be00dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=9, prompt_tokens=17, total_tokens=26), 'model': '', 'finish_reason': 'stop'}, id='run-333bf83d-89a5-49b2-87d4-2b95ae976821-0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "chat.invoke(\"What is the capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Past messages:\n",
    "{message_buffer_log}\n",
    "\n",
    "Conversation summary:\n",
    "{message_summary_log}\n",
    "\n",
    "Human: {question}\n",
    "AI:\n",
    "'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template = TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_buffer_memory = ConversationBufferMemory(memory_key = 'message_buffer_log', \n",
    "                                              input_key = 'question',\n",
    "                                              return_messages = False)\n",
    "\n",
    "chat_summary_memory = ConversationSummaryMemory(llm = ChatHuggingFace(llm=llm, verbose=True), \n",
    "                                                memory_key = 'message_summary_log', \n",
    "                                                input_key = 'question',\n",
    "                                                return_messages = False)\n",
    "\n",
    "chat_combined_memory = CombinedMemory(memories = [chat_buffer_memory, \n",
    "                                                  chat_summary_memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_buffer_log': '', 'message_summary_log': ''}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print(chat_combined_memory.load_memory_variables({})['message_summary_log'])\n",
    "chat_combined_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm = chat, \n",
    "                 prompt = prompt_template, \n",
    "                 memory = chat_combined_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me an interesting fact I probably didn't know about?\n",
      "AI: Sure! Did you know that despite its reputation for being shy, the octopus has a sophisticated sense of humor? Observations have shown that they'll often play tricks on predators and other octopuses in small underwater communities, surprisingly engaging in what some scientists call \"theater action.” They also indulge in a bit of light-hearted fun by performing these pranks on their siblings as a way to reduce tension and avoid harm\n",
      "\n",
      "Conversation summary:\n",
      "The human asks for an interesting fact. The AI provides a fascinating tidbit about octopuses, sharing that despite being thought of as shy, they actually possess a sophisticated sense of humor, engaging in play with pranks both to entertain themselves and to manage conflicts with family members.\n",
      "\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks for an interesting fact. The AI provides a fascinating tidbit about octopuses, sharing that despite being thought of as shy, they actually possess a sophisticated sense of humor, engaging in play with pranks both to entertain themselves and to manage conflicts with family members.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI: I'm happy to dive deeper into the fascinating world of octopus humor! According to Dr. Jennifer Mather, an expert in cephalopod intelligence, these clever creatures have been observed displaying a range of playful behaviors, including releasing a cloud of ink to \"fog\" the area and then quickly changing color to escape detection. They've even been known to play a game of \"hide and seek\" with pirates, hiding in underwater crevices and suddenly emerging when they think the danger has\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this fact?',\n",
       " 'message_buffer_log': 'Human: Can you give me an interesting fact I probably didn\\'t know about?\\nAI: Sure! Did you know that despite its reputation for being shy, the octopus has a sophisticated sense of humor? Observations have shown that they\\'ll often play tricks on predators and other octopuses in small underwater communities, surprisingly engaging in what some scientists call \"theater action.” They also indulge in a bit of light-hearted fun by performing these pranks on their siblings as a way to reduce tension and avoid harm',\n",
       " 'message_summary_log': 'The human asks for an interesting fact. The AI provides a fascinating tidbit about octopuses, sharing that despite being thought of as shy, they actually possess a sophisticated sense of humor, engaging in play with pranks both to entertain themselves and to manage conflicts with family members.',\n",
       " 'text': 'I\\'m happy to dive deeper into the fascinating world of octopus humor! According to Dr. Jennifer Mather, an expert in cephalopod intelligence, these clever creatures have been observed displaying a range of playful behaviors, including releasing a cloud of ink to \"fog\" the area and then quickly changing color to escape detection. They\\'ve even been known to play a game of \"hide and seek\" with pirates, hiding in underwater crevices and suddenly emerging when they think the danger has'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chain.invoke({'question':'''Can you give me an interesting fact I probably didn't know about?'''})\n",
    "chain.invoke({'question':'''Can you elaborate a bit more on this fact?'''})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
